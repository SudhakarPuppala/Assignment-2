{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# M3: CI Pipeline for Build, Test & Image Creation\n",
    "\n",
    "**Objective:** Implement Continuous Integration to automatically test, package, and build container images.\n",
    "\n",
    "**Tasks:**\n",
    "1. Automated Testing (pytest)\n",
    "2. CI Setup (GitHub Actions)\n",
    "3. Artifact Publishing (Docker Hub)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Imports successful!\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import subprocess\n",
    "import json\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "\n",
    "sys.path.append(os.path.abspath('..'))\n",
    "\n",
    "print(\"✓ Imports successful!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Review Test Structure\n",
    "\n",
    "Our project has comprehensive unit tests organized in the `tests/` directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Files:\n",
      "==================================================\n",
      "  test_api.py                               141 lines\n",
      "  test_model.py                             231 lines\n",
      "  test_preprocessing.py                     173 lines\n",
      "\n",
      "Total test files: 3\n"
     ]
    }
   ],
   "source": [
    "# List all test files\n",
    "test_dir = '../tests'\n",
    "test_files = [f for f in os.listdir(test_dir) if f.startswith('test_') and f.endswith('.py')]\n",
    "\n",
    "print(\"Test Files:\")\n",
    "print(\"=\" * 50)\n",
    "for test_file in sorted(test_files):\n",
    "    filepath = os.path.join(test_dir, test_file)\n",
    "    with open(filepath, 'r') as f:\n",
    "        lines = len(f.readlines())\n",
    "    print(f\"  {test_file:<40} {lines:>4} lines\")\n",
    "\n",
    "print(f\"\\nTotal test files: {len(test_files)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Run Unit Tests\n",
    "\n",
    "Execute all unit tests using pytest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running unit tests...\n",
      "\n",
      "\u001b[1m============================= test session starts ==============================\u001b[0m\n",
      "platform darwin -- Python 3.13.5, pytest-9.0.2, pluggy-1.5.0 -- /opt/miniconda3/bin/python3.13\n",
      "cachedir: .pytest_cache\n",
      "rootdir: /Users/tanwin/Desktop/BITS-Mtech/Semester-3/MLO/Assignment-2\n",
      "configfile: pytest.ini\n",
      "plugins: anyio-4.12.1, hydra-core-1.3.2, cov-7.0.0\n",
      "\u001b[1mcollecting ... \u001b[0mcollected 34 items\n",
      "\n",
      "../tests/test_api.py::TestAPIEndpoints::test_root_endpoint \u001b[32mPASSED\u001b[0m\u001b[32m        [  2%]\u001b[0m\n",
      "../tests/test_api.py::TestAPIEndpoints::test_health_check \u001b[32mPASSED\u001b[0m\u001b[32m         [  5%]\u001b[0m\n",
      "../tests/test_api.py::TestAPIEndpoints::test_model_info \u001b[32mPASSED\u001b[0m\u001b[32m           [  8%]\u001b[0m\n",
      "../tests/test_api.py::TestAPIEndpoints::test_metrics_endpoint \u001b[32mPASSED\u001b[0m\u001b[32m     [ 11%]\u001b[0m\n",
      "../tests/test_api.py::TestPredictionEndpoint::test_predict_with_valid_image \u001b[32mPASSED\u001b[0m\u001b[32m [ 14%]\u001b[0m\n",
      "../tests/test_api.py::TestPredictionEndpoint::test_predict_without_file \u001b[32mPASSED\u001b[0m\u001b[32m [ 17%]\u001b[0m\n",
      "../tests/test_api.py::TestPredictionEndpoint::test_predict_with_invalid_file_type \u001b[32mPASSED\u001b[0m\u001b[32m [ 20%]\u001b[0m\n",
      "../tests/test_api.py::TestAPIResponseFormat::test_health_response_format \u001b[32mPASSED\u001b[0m\u001b[32m [ 23%]\u001b[0m\n",
      "../tests/test_api.py::TestAPIResponseFormat::test_prediction_response_format \u001b[32mPASSED\u001b[0m\u001b[32m [ 26%]\u001b[0m\n",
      "../tests/test_model.py::TestModelArchitecture::test_model_initialization \u001b[32mPASSED\u001b[0m\u001b[32m [ 29%]\u001b[0m\n",
      "../tests/test_model.py::TestModelArchitecture::test_model_forward_pass \u001b[32mPASSED\u001b[0m\u001b[32m [ 32%]\u001b[0m\n",
      "../tests/test_model.py::TestModelArchitecture::test_model_output_range \u001b[32mPASSED\u001b[0m\u001b[32m [ 35%]\u001b[0m\n",
      "../tests/test_model.py::TestModelArchitecture::test_model_parameters \u001b[32mPASSED\u001b[0m\u001b[32m [ 38%]\u001b[0m\n",
      "../tests/test_model.py::TestModelArchitecture::test_model_different_num_classes \u001b[32mPASSED\u001b[0m\u001b[32m [ 41%]\u001b[0m\n",
      "../tests/test_model.py::TestModelArchitecture::test_get_model_function \u001b[32mPASSED\u001b[0m\u001b[32m [ 44%]\u001b[0m\n",
      "../tests/test_model.py::TestModelArchitecture::test_model_get_info \u001b[32mPASSED\u001b[0m\u001b[32m [ 47%]\u001b[0m\n",
      "../tests/test_model.py::TestModelSaveLoad::test_save_model \u001b[32mPASSED\u001b[0m\u001b[32m        [ 50%]\u001b[0m\n",
      "../tests/test_model.py::TestModelSaveLoad::test_load_model \u001b[32mPASSED\u001b[0m\u001b[32m        [ 52%]\u001b[0m\n",
      "../tests/test_model.py::TestModelSaveLoad::test_save_load_preserves_weights \u001b[32mPASSED\u001b[0m\u001b[32m [ 55%]\u001b[0m\n",
      "../tests/test_model.py::TestModelInference::test_inference_mode \u001b[32mPASSED\u001b[0m\u001b[32m   [ 58%]\u001b[0m\n",
      "../tests/test_model.py::TestModelInference::test_batch_inference \u001b[32mPASSED\u001b[0m\u001b[32m  [ 61%]\u001b[0m\n",
      "../tests/test_model.py::TestModelInference::test_prediction_consistency \u001b[32mPASSED\u001b[0m\u001b[32m [ 64%]\u001b[0m\n",
      "../tests/test_model.py::TestModelInference::test_softmax_probabilities \u001b[32mPASSED\u001b[0m\u001b[32m [ 67%]\u001b[0m\n",
      "../tests/test_model.py::TestModelGradients::test_backward_pass \u001b[32mPASSED\u001b[0m\u001b[32m    [ 70%]\u001b[0m\n",
      "../tests/test_preprocessing.py::TestDataPreprocessing::test_normalize_image \u001b[32mPASSED\u001b[0m\u001b[32m [ 73%]\u001b[0m\n",
      "../tests/test_preprocessing.py::TestDataPreprocessing::test_denormalize_image \u001b[32mPASSED\u001b[0m\u001b[32m [ 76%]\u001b[0m\n",
      "../tests/test_preprocessing.py::TestDataPreprocessing::test_normalize_denormalize_inverse \u001b[32mPASSED\u001b[0m\u001b[32m [ 79%]\u001b[0m\n",
      "../tests/test_preprocessing.py::TestDataPreprocessing::test_get_transforms_training \u001b[32mPASSED\u001b[0m\u001b[32m [ 82%]\u001b[0m\n",
      "../tests/test_preprocessing.py::TestDataPreprocessing::test_get_transforms_validation \u001b[32mPASSED\u001b[0m\u001b[32m [ 85%]\u001b[0m\n",
      "../tests/test_preprocessing.py::TestDataPreprocessing::test_transforms_output_shape \u001b[32mPASSED\u001b[0m\u001b[32m [ 88%]\u001b[0m\n",
      "../tests/test_preprocessing.py::TestDataPreprocessing::test_cats_dogs_dataset \u001b[32mPASSED\u001b[0m\u001b[32m [ 91%]\u001b[0m\n",
      "../tests/test_preprocessing.py::TestDataProcessingEdgeCases::test_normalize_single_channel \u001b[32mPASSED\u001b[0m\u001b[32m [ 94%]\u001b[0m\n",
      "../tests/test_preprocessing.py::TestDataProcessingEdgeCases::test_normalize_empty_image \u001b[32mPASSED\u001b[0m\u001b[32m [ 97%]\u001b[0m\n",
      "../tests/test_preprocessing.py::TestDataProcessingEdgeCases::test_transforms_different_aspect_ratios \u001b[32mPASSED\u001b[0m\u001b[32m [100%]\u001b[0m\n",
      "\n",
      "================================ tests coverage ================================\n",
      "_______________ coverage: platform darwin, python 3.13.5-final-0 _______________\n",
      "\n",
      "Name                                                                                     Stmts   Miss  Cover   Missing\n",
      "----------------------------------------------------------------------------------------------------------------------\n",
      "/Users/tanwin/Desktop/BITS-Mtech/Semester-3/MLO/Assignment-2/src/__init__.py                 0      0   100%\n",
      "/Users/tanwin/Desktop/BITS-Mtech/Semester-3/MLO/Assignment-2/src/data_preprocessing.py      43     13    70%   34-41, 96-127\n",
      "/Users/tanwin/Desktop/BITS-Mtech/Semester-3/MLO/Assignment-2/src/inference_api.py           91     31    66%   49-71, 78-79, 120, 154-176, 206-209, 221-222\n",
      "/Users/tanwin/Desktop/BITS-Mtech/Semester-3/MLO/Assignment-2/src/model.py                   56      0   100%\n",
      "/Users/tanwin/Desktop/BITS-Mtech/Semester-3/MLO/Assignment-2/src/train.py                  152    152     0%   4-287\n",
      "----------------------------------------------------------------------------------------------------------------------\n",
      "TOTAL                                                                                      342    196    43%\n",
      "Coverage HTML written to dir htmlcov\n",
      "\u001b[32m============================== \u001b[32m\u001b[1m34 passed\u001b[0m\u001b[32m in 7.27s\u001b[0m\u001b[32m ==============================\u001b[0m\n",
      "\n",
      "\n",
      "✓ All tests passed!\n"
     ]
    }
   ],
   "source": [
    "# Run pytest\n",
    "print(\"Running unit tests...\\n\")\n",
    "\n",
    "result = subprocess.run(\n",
    "    ['pytest', '../tests/', '-v', '--tb=short'],\n",
    "    capture_output=True,\n",
    "    text=True\n",
    ")\n",
    "\n",
    "print(result.stdout)\n",
    "if result.stderr:\n",
    "    print(\"STDERR:\", result.stderr)\n",
    "\n",
    "if result.returncode == 0:\n",
    "    print(\"\\n✓ All tests passed!\")\n",
    "else:\n",
    "    print(\"\\n✗ Some tests failed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Run Tests with Coverage\n",
    "\n",
    "Check test coverage for the source code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running tests with coverage...\n",
      "\n",
      "\u001b[1m============================= test session starts ==============================\u001b[0m\n",
      "platform darwin -- Python 3.13.5, pytest-9.0.2, pluggy-1.5.0 -- /opt/miniconda3/bin/python3.13\n",
      "cachedir: .pytest_cache\n",
      "rootdir: /Users/tanwin/Desktop/BITS-Mtech/Semester-3/MLO/Assignment-2\n",
      "configfile: pytest.ini\n",
      "plugins: anyio-4.12.1, hydra-core-1.3.2, cov-7.0.0\n",
      "\u001b[1mcollecting ... \u001b[0mcollected 34 items\n",
      "\n",
      "../tests/test_api.py::TestAPIEndpoints::test_root_endpoint \u001b[32mPASSED\u001b[0m\u001b[32m        [  2%]\u001b[0m\n",
      "../tests/test_api.py::TestAPIEndpoints::test_health_check \u001b[32mPASSED\u001b[0m\u001b[32m         [  5%]\u001b[0m\n",
      "../tests/test_api.py::TestAPIEndpoints::test_model_info \u001b[32mPASSED\u001b[0m\u001b[32m           [  8%]\u001b[0m\n",
      "../tests/test_api.py::TestAPIEndpoints::test_metrics_endpoint \u001b[32mPASSED\u001b[0m\u001b[32m     [ 11%]\u001b[0m\n",
      "../tests/test_api.py::TestPredictionEndpoint::test_predict_with_valid_image \u001b[32mPASSED\u001b[0m\u001b[32m [ 14%]\u001b[0m\n",
      "../tests/test_api.py::TestPredictionEndpoint::test_predict_without_file \u001b[32mPASSED\u001b[0m\u001b[32m [ 17%]\u001b[0m\n",
      "../tests/test_api.py::TestPredictionEndpoint::test_predict_with_invalid_file_type \u001b[32mPASSED\u001b[0m\u001b[32m [ 20%]\u001b[0m\n",
      "../tests/test_api.py::TestAPIResponseFormat::test_health_response_format \u001b[32mPASSED\u001b[0m\u001b[32m [ 23%]\u001b[0m\n",
      "../tests/test_api.py::TestAPIResponseFormat::test_prediction_response_format \u001b[32mPASSED\u001b[0m\u001b[32m [ 26%]\u001b[0m\n",
      "../tests/test_model.py::TestModelArchitecture::test_model_initialization \u001b[32mPASSED\u001b[0m\u001b[32m [ 29%]\u001b[0m\n",
      "../tests/test_model.py::TestModelArchitecture::test_model_forward_pass \u001b[32mPASSED\u001b[0m\u001b[32m [ 32%]\u001b[0m\n",
      "../tests/test_model.py::TestModelArchitecture::test_model_output_range \u001b[32mPASSED\u001b[0m\u001b[32m [ 35%]\u001b[0m\n",
      "../tests/test_model.py::TestModelArchitecture::test_model_parameters \u001b[32mPASSED\u001b[0m\u001b[32m [ 38%]\u001b[0m\n",
      "../tests/test_model.py::TestModelArchitecture::test_model_different_num_classes \u001b[32mPASSED\u001b[0m\u001b[32m [ 41%]\u001b[0m\n",
      "../tests/test_model.py::TestModelArchitecture::test_get_model_function \u001b[32mPASSED\u001b[0m\u001b[32m [ 44%]\u001b[0m\n",
      "../tests/test_model.py::TestModelArchitecture::test_model_get_info \u001b[32mPASSED\u001b[0m\u001b[32m [ 47%]\u001b[0m\n",
      "../tests/test_model.py::TestModelSaveLoad::test_save_model \u001b[32mPASSED\u001b[0m\u001b[32m        [ 50%]\u001b[0m\n",
      "../tests/test_model.py::TestModelSaveLoad::test_load_model \u001b[32mPASSED\u001b[0m\u001b[32m        [ 52%]\u001b[0m\n",
      "../tests/test_model.py::TestModelSaveLoad::test_save_load_preserves_weights \u001b[32mPASSED\u001b[0m\u001b[32m [ 55%]\u001b[0m\n",
      "../tests/test_model.py::TestModelInference::test_inference_mode \u001b[32mPASSED\u001b[0m\u001b[32m   [ 58%]\u001b[0m\n",
      "../tests/test_model.py::TestModelInference::test_batch_inference \u001b[32mPASSED\u001b[0m\u001b[32m  [ 61%]\u001b[0m\n",
      "../tests/test_model.py::TestModelInference::test_prediction_consistency \u001b[32mPASSED\u001b[0m\u001b[32m [ 64%]\u001b[0m\n",
      "../tests/test_model.py::TestModelInference::test_softmax_probabilities \u001b[32mPASSED\u001b[0m\u001b[32m [ 67%]\u001b[0m\n",
      "../tests/test_model.py::TestModelGradients::test_backward_pass \u001b[32mPASSED\u001b[0m\u001b[32m    [ 70%]\u001b[0m\n",
      "../tests/test_preprocessing.py::TestDataPreprocessing::test_normalize_image \u001b[32mPASSED\u001b[0m\u001b[32m [ 73%]\u001b[0m\n",
      "../tests/test_preprocessing.py::TestDataPreprocessing::test_denormalize_image \u001b[32mPASSED\u001b[0m\u001b[32m [ 76%]\u001b[0m\n",
      "../tests/test_preprocessing.py::TestDataPreprocessing::test_normalize_denormalize_inverse \u001b[32mPASSED\u001b[0m\u001b[32m [ 79%]\u001b[0m\n",
      "../tests/test_preprocessing.py::TestDataPreprocessing::test_get_transforms_training \u001b[32mPASSED\u001b[0m\u001b[32m [ 82%]\u001b[0m\n",
      "../tests/test_preprocessing.py::TestDataPreprocessing::test_get_transforms_validation \u001b[32mPASSED\u001b[0m\u001b[32m [ 85%]\u001b[0m\n",
      "../tests/test_preprocessing.py::TestDataPreprocessing::test_transforms_output_shape \u001b[32mPASSED\u001b[0m\u001b[32m [ 88%]\u001b[0m\n",
      "../tests/test_preprocessing.py::TestDataPreprocessing::test_cats_dogs_dataset \u001b[32mPASSED\u001b[0m\u001b[32m [ 91%]\u001b[0m\n",
      "../tests/test_preprocessing.py::TestDataProcessingEdgeCases::test_normalize_single_channel \u001b[32mPASSED\u001b[0m\u001b[32m [ 94%]\u001b[0m\n",
      "../tests/test_preprocessing.py::TestDataProcessingEdgeCases::test_normalize_empty_image \u001b[32mPASSED\u001b[0m\u001b[32m [ 97%]\u001b[0m\n",
      "../tests/test_preprocessing.py::TestDataProcessingEdgeCases::test_transforms_different_aspect_ratios \u001b[32mPASSED\u001b[0m\u001b[32m [100%]\u001b[0m\n",
      "\n",
      "================================ tests coverage ================================\n",
      "_______________ coverage: platform darwin, python 3.13.5-final-0 _______________\n",
      "\n",
      "Name                                                                                     Stmts   Miss  Cover   Missing\n",
      "----------------------------------------------------------------------------------------------------------------------\n",
      "/Users/tanwin/Desktop/BITS-Mtech/Semester-3/MLO/Assignment-2/src/__init__.py                 0      0   100%\n",
      "/Users/tanwin/Desktop/BITS-Mtech/Semester-3/MLO/Assignment-2/src/data_preprocessing.py      43     13    70%   34-41, 96-127\n",
      "/Users/tanwin/Desktop/BITS-Mtech/Semester-3/MLO/Assignment-2/src/inference_api.py           91     31    66%   49-71, 78-79, 120, 154-176, 206-209, 221-222\n",
      "/Users/tanwin/Desktop/BITS-Mtech/Semester-3/MLO/Assignment-2/src/model.py                   56      0   100%\n",
      "/Users/tanwin/Desktop/BITS-Mtech/Semester-3/MLO/Assignment-2/src/train.py                  152    152     0%   4-287\n",
      "----------------------------------------------------------------------------------------------------------------------\n",
      "TOTAL                                                                                      342    196    43%\n",
      "Coverage HTML written to dir htmlcov\n",
      "\u001b[32m============================== \u001b[32m\u001b[1m34 passed\u001b[0m\u001b[32m in 7.31s\u001b[0m\u001b[32m ==============================\u001b[0m\n",
      "\n",
      "\n",
      "✓ Coverage report generated!\n"
     ]
    }
   ],
   "source": [
    "# Run pytest with coverage\n",
    "print(\"Running tests with coverage...\\n\")\n",
    "\n",
    "result = subprocess.run(\n",
    "    ['pytest', '../tests/', '--cov=../src', '--cov-report=term-missing'],\n",
    "    capture_output=True,\n",
    "    text=True\n",
    ")\n",
    "\n",
    "print(result.stdout)\n",
    "\n",
    "if result.returncode == 0:\n",
    "    print(\"\\n✓ Coverage report generated!\")\n",
    "else:\n",
    "    print(\"\\n⚠ Coverage report may be incomplete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Test Categories\n",
    "\n",
    "Our tests are organized into three categories:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Summary:\n",
      "==================================================\n",
      "  test_api.py                                9 tests\n",
      "  test_model.py                             15 tests\n",
      "  test_preprocessing.py                     10 tests\n",
      "==================================================\n",
      "  Total                                     34 tests\n"
     ]
    }
   ],
   "source": [
    "# Count tests in each file\n",
    "import ast\n",
    "\n",
    "def count_tests_in_file(filepath):\n",
    "    \"\"\"Count test functions in a Python file\"\"\"\n",
    "    with open(filepath, 'r') as f:\n",
    "        tree = ast.parse(f.read())\n",
    "    \n",
    "    test_count = 0\n",
    "    for node in ast.walk(tree):\n",
    "        if isinstance(node, ast.FunctionDef) and node.name.startswith('test_'):\n",
    "            test_count += 1\n",
    "    \n",
    "    return test_count\n",
    "\n",
    "test_summary = {}\n",
    "total_tests = 0\n",
    "\n",
    "for test_file in test_files:\n",
    "    filepath = os.path.join(test_dir, test_file)\n",
    "    count = count_tests_in_file(filepath)\n",
    "    test_summary[test_file] = count\n",
    "    total_tests += count\n",
    "\n",
    "print(\"Test Summary:\")\n",
    "print(\"=\" * 50)\n",
    "for filename, count in sorted(test_summary.items()):\n",
    "    print(f\"  {filename:<40} {count:>3} tests\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"  {'Total':<40} {total_tests:>3} tests\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Review GitHub Actions Workflow\n",
    "\n",
    "Check the CI/CD pipeline configuration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GitHub Actions CI/CD Workflow:\n",
      "==================================================\n",
      "name: CI/CD Pipeline\n",
      "\n",
      "on:\n",
      "  push:\n",
      "    branches: [ main ]\n",
      "  pull_request:\n",
      "    branches: [ main ]\n",
      "\n",
      "jobs:\n",
      "  build-test:\n",
      "    runs-on: ubuntu-latest\n",
      "    steps:\n",
      "      - name: Checkout code\n",
      "        uses: actions/checkout@v4\n",
      "\n",
      "      - name: Set up Python\n",
      "        uses: actions/setup-python@v5\n",
      "        with:\n",
      "          python-version: '3.10'\n",
      "\n",
      "      - name: Install dependencies\n",
      "        run: |\n",
      "          python -m pip install --upgrade pip\n",
      "          pip install -r requirements.txt\n",
      "\n",
      "      - name: Run tests\n",
      "        run: |\n",
      "          pytest --maxfail=1 --disable-warnings -q\n",
      "\n",
      "  build-docker-image:\n",
      "    needs: build-test\n",
      "    runs-on: ubuntu-latest\n",
      "    steps:\n",
      "      - name: Checkout code\n",
      "        uses: actions/checkout@v4\n",
      "\n",
      "      - name: Set up Docker Buildx\n",
      "        uses: docker/setup-buildx-action@v3\n",
      "\n",
      "      - name: Login to DockerHub\n",
      "        uses: docker/login-action@v3\n",
      "        with:\n",
      "          username: ${{ secrets.DOCKERHUB_USERNAME }}\n",
      "          password: ${{ secrets.DOCKERHUB_TOKEN }}\n",
      "\n",
      "      - name: Build and push Docker image\n",
      "        uses: docker/build-push-action@v5\n",
      "        with:\n",
      "          context: .\n",
      "          push: true\n",
      "          tags: ${{ secrets.DOCKERHUB_USERNAME }}/cats-dogs-classifier:latest\n",
      "\n",
      "\n",
      "==================================================\n",
      "Workflow file size: 1195 characters\n",
      "Lines: 51\n"
     ]
    }
   ],
   "source": [
    "# Display GitHub Actions workflow\n",
    "workflow_path = '../.github/workflows/ci-cd.yml'\n",
    "\n",
    "with open(workflow_path, 'r') as f:\n",
    "    workflow = f.read()\n",
    "\n",
    "print(\"GitHub Actions CI/CD Workflow:\")\n",
    "print(\"=\" * 50)\n",
    "print(workflow)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 50)\n",
    "print(f\"Workflow file size: {len(workflow)} characters\")\n",
    "print(f\"Lines: {len(workflow.splitlines())}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. CI Pipeline Jobs\n",
    "\n",
    "Our GitHub Actions workflow consists of 3 jobs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CI/CD Pipeline Jobs:\n",
      "============================================================\n",
      "\n",
      "1. Test\n",
      "  Trigger: On every push and pull request\n",
      "  Steps:\n",
      "    - Checkout code\n",
      "    - Setup Python 3.10\n",
      "    - Cache pip dependencies\n",
      "    - Install dependencies\n",
      "    - Run unit tests with pytest\n",
      "    - Upload coverage reports\n",
      "\n",
      "2. Build and Push\n",
      "  Trigger: On push to main branch (after tests pass)\n",
      "  Steps:\n",
      "    - Checkout code\n",
      "    - Setup Docker Buildx\n",
      "    - Login to Docker Hub\n",
      "    - Extract metadata\n",
      "    - Build Docker image\n",
      "    - Push to Docker Hub\n",
      "    - Tag: latest, branch name, SHA\n",
      "\n",
      "3. Deploy (Optional)\n",
      "  Trigger: On main branch (after build)\n",
      "  Steps:\n",
      "    - Setup kubectl\n",
      "    - Configure kubeconfig\n",
      "    - Deploy to Kubernetes\n",
      "    - Run smoke tests\n"
     ]
    }
   ],
   "source": [
    "pipeline_jobs = {\n",
    "    \"1. Test\": {\n",
    "        \"trigger\": \"On every push and pull request\",\n",
    "        \"steps\": [\n",
    "            \"Checkout code\",\n",
    "            \"Setup Python 3.10\",\n",
    "            \"Cache pip dependencies\",\n",
    "            \"Install dependencies\",\n",
    "            \"Run unit tests with pytest\",\n",
    "            \"Upload coverage reports\"\n",
    "        ]\n",
    "    },\n",
    "    \"2. Build and Push\": {\n",
    "        \"trigger\": \"On push to main branch (after tests pass)\",\n",
    "        \"steps\": [\n",
    "            \"Checkout code\",\n",
    "            \"Setup Docker Buildx\",\n",
    "            \"Login to Docker Hub\",\n",
    "            \"Extract metadata\",\n",
    "            \"Build Docker image\",\n",
    "            \"Push to Docker Hub\",\n",
    "            \"Tag: latest, branch name, SHA\"\n",
    "        ]\n",
    "    },\n",
    "    \"3. Deploy (Optional)\": {\n",
    "        \"trigger\": \"On main branch (after build)\",\n",
    "        \"steps\": [\n",
    "            \"Setup kubectl\",\n",
    "            \"Configure kubeconfig\",\n",
    "            \"Deploy to Kubernetes\",\n",
    "            \"Run smoke tests\"\n",
    "        ]\n",
    "    }\n",
    "}\n",
    "\n",
    "print(\"CI/CD Pipeline Jobs:\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "for job_name, job_details in pipeline_jobs.items():\n",
    "    print(f\"\\n{job_name}\")\n",
    "    print(f\"  Trigger: {job_details['trigger']}\")\n",
    "    print(f\"  Steps:\")\n",
    "    for step in job_details['steps']:\n",
    "        print(f\"    - {step}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Setup GitHub Secrets\n",
    "\n",
    "For the CI/CD pipeline to work, you need to configure GitHub Secrets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Required GitHub Secrets:\n",
      "============================================================\n",
      "\n",
      "1. DOCKERHUB_USERNAME\n",
      "   Description: Your Docker Hub username\n",
      "   How to get: Visit https://hub.docker.com\n",
      "\n",
      "2. DOCKERHUB_TOKEN\n",
      "   Description: Docker Hub access token\n",
      "   How to get:\n",
      "     1. Log into Docker Hub\n",
      "     2. Go to Account Settings > Security\n",
      "     3. Create New Access Token\n",
      "     4. Copy the token\n",
      ".       dckr_pat_U09-oM-n-AJ-UYKmrgmJAcDTF8A\n",
      "\n",
      "3. KUBECONFIG (Optional - for deployment)\n",
      "   Description: Kubernetes cluster configuration\n",
      "   How to get: Copy contents of ~/.kube/config\n",
      "\n",
      "============================================================\n",
      "\n",
      "How to add secrets to GitHub:\n",
      "  1. Go to your GitHub repository\n",
      "  2. Settings > Secrets and variables > Actions\n",
      "  3. Click 'New repository secret'\n",
      "  4. Add each secret with its value\n"
     ]
    }
   ],
   "source": [
    "print(\"Required GitHub Secrets:\")\n",
    "print(\"=\" * 60)\n",
    "print(\"\\n1. DOCKERHUB_USERNAME\")\n",
    "print(\"   Description: Your Docker Hub username\")\n",
    "print(\"   How to get: Visit https://hub.docker.com\")\n",
    "print(\"\\n2. DOCKERHUB_TOKEN\")\n",
    "print(\"   Description: Docker Hub access token\")\n",
    "print(\"   How to get:\")\n",
    "print(\"     1. Log into Docker Hub\")\n",
    "print(\"     2. Go to Account Settings > Security\")\n",
    "print(\"     3. Create New Access Token\")\n",
    "print(\"     4. Copy the token\")\n",
    "print(\".       dckr_pat_U09-oM-n-AJ-UYKmrgmJAcDTF8A\")\n",
    "print(\"\\n3. KUBECONFIG (Optional - for deployment)\")\n",
    "print(\"   Description: Kubernetes cluster configuration\")\n",
    "print(\"   How to get: Copy contents of ~/.kube/config\")\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"\\nHow to add secrets to GitHub:\")\n",
    "print(\"  1. Go to your GitHub repository\")\n",
    "print(\"  2. Settings > Secrets and variables > Actions\")\n",
    "print(\"  3. Click 'New repository secret'\")\n",
    "print(\"  4. Add each secret with its value\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Test Docker Build Locally\n",
    "\n",
    "Before pushing to CI, test Docker build locally."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Local Docker Build Test:\n",
      "============================================================\n",
      "\n",
      "Command:\n",
      "cd .. && docker build -t cats-dogs-classifier:test .\n",
      "\n",
      "What this does:\n",
      "  1. Uses Dockerfile in project root\n",
      "  2. Builds image with tag 'test'\n",
      "  3. Installs all dependencies\n",
      "  4. Copies source code and models\n",
      "  5. Sets up health checks\n",
      "\n",
      "Expected output:\n",
      "  - Multiple build steps\n",
      "  - Successfully built <image-id>\n",
      "  - Successfully tagged cats-dogs-classifier:test\n",
      "\n",
      "To run the built image:\n",
      "docker run -d -p 8000:8000 cats-dogs-classifier:test\n"
     ]
    }
   ],
   "source": [
    "# Docker build command\n",
    "print(\"Local Docker Build Test:\")\n",
    "print(\"=\" * 60)\n",
    "print(\"\\nCommand:\")\n",
    "print(\"cd .. && docker build -t cats-dogs-classifier:test .\")\n",
    "print(\"\\nWhat this does:\")\n",
    "print(\"  1. Uses Dockerfile in project root\")\n",
    "print(\"  2. Builds image with tag 'test'\")\n",
    "print(\"  3. Installs all dependencies\")\n",
    "print(\"  4. Copies source code and models\")\n",
    "print(\"  5. Sets up health checks\")\n",
    "print(\"\\nExpected output:\")\n",
    "print(\"  - Multiple build steps\")\n",
    "print(\"  - Successfully built <image-id>\")\n",
    "print(\"  - Successfully tagged cats-dogs-classifier:test\")\n",
    "print(\"\\nTo run the built image:\")\n",
    "print(\"docker run -d -p 8000:8000 cats-dogs-classifier:test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Trigger CI Pipeline\n",
    "\n",
    "Once everything is set up, trigger the CI pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "How to Trigger CI Pipeline:\n",
      "============================================================\n",
      "\n",
      "1. Make sure you have:\n",
      "   ✓ GitHub repository created\n",
      "   ✓ GitHub secrets configured\n",
      "   ✓ All code committed\n",
      "\n",
      "2. Push to trigger pipeline:\n",
      "   git add .\n",
      "   git commit -m 'Trigger CI pipeline'\n",
      "   git push origin main\n",
      "\n",
      "3. View pipeline:\n",
      "   - Go to GitHub repository\n",
      "   - Click 'Actions' tab\n",
      "   - See workflow runs\n",
      "\n",
      "4. Expected flow:\n",
      "   Job 1: Test (always runs)\n",
      "     └─ Install deps → Run tests → Upload coverage\n",
      "   Job 2: Build and Push (if tests pass, main branch only)\n",
      "     └─ Build Docker → Push to registry\n",
      "   Job 3: Deploy (optional, main branch only)\n",
      "     └─ Deploy to K8s → Run smoke tests\n"
     ]
    }
   ],
   "source": [
    "print(\"How to Trigger CI Pipeline:\")\n",
    "print(\"=\" * 60)\n",
    "print(\"\\n1. Make sure you have:\")\n",
    "print(\"   ✓ GitHub repository created\")\n",
    "print(\"   ✓ GitHub secrets configured\")\n",
    "print(\"   ✓ All code committed\")\n",
    "print(\"\\n2. Push to trigger pipeline:\")\n",
    "print(\"   git add .\")\n",
    "print(\"   git commit -m 'Trigger CI pipeline'\")\n",
    "print(\"   git push origin main\")\n",
    "print(\"\\n3. View pipeline:\")\n",
    "print(\"   - Go to GitHub repository\")\n",
    "print(\"   - Click 'Actions' tab\")\n",
    "print(\"   - See workflow runs\")\n",
    "print(\"\\n4. Expected flow:\")\n",
    "print(\"   Job 1: Test (always runs)\")\n",
    "print(\"     └─ Install deps → Run tests → Upload coverage\")\n",
    "print(\"   Job 2: Build and Push (if tests pass, main branch only)\")\n",
    "print(\"     └─ Build Docker → Push to registry\")\n",
    "print(\"   Job 3: Deploy (optional, main branch only)\")\n",
    "print(\"     └─ Deploy to K8s → Run smoke tests\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. View CI Pipeline Results\n",
    "\n",
    "Monitor and analyze pipeline results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CI Pipeline Monitoring:\n",
      "============================================================\n",
      "\n",
      "1. GitHub Actions Dashboard\n",
      "   URL: https://github.com/<username>/<repo>/actions\n",
      "   Shows:\n",
      "     - All workflow runs\n",
      "     - Success/failure status\n",
      "     - Execution time\n",
      "     - Detailed logs\n",
      "\n",
      "2. Test Results\n",
      "   - Number of tests run\n",
      "   - Pass/fail status\n",
      "   - Coverage percentage\n",
      "\n",
      "3. Docker Image\n",
      "   URL: https://hub.docker.com\n",
      "   Shows:\n",
      "     - Published images\n",
      "     - Image tags\n",
      "     - Image size\n",
      "     - Pull count\n",
      "\n",
      "4. Build Artifacts\n",
      "   - Docker images in registry\n",
      "   - Coverage reports\n",
      "   - Test results\n"
     ]
    }
   ],
   "source": [
    "print(\"CI Pipeline Monitoring:\")\n",
    "print(\"=\" * 60)\n",
    "print(\"\\n1. GitHub Actions Dashboard\")\n",
    "print(\"   URL: https://github.com/<username>/<repo>/actions\")\n",
    "print(\"   Shows:\")\n",
    "print(\"     - All workflow runs\")\n",
    "print(\"     - Success/failure status\")\n",
    "print(\"     - Execution time\")\n",
    "print(\"     - Detailed logs\")\n",
    "print(\"\\n2. Test Results\")\n",
    "print(\"   - Number of tests run\")\n",
    "print(\"   - Pass/fail status\")\n",
    "print(\"   - Coverage percentage\")\n",
    "print(\"\\n3. Docker Image\")\n",
    "print(\"   URL: https://hub.docker.com\")\n",
    "print(\"   Shows:\")\n",
    "print(\"     - Published images\")\n",
    "print(\"     - Image tags\")\n",
    "print(\"     - Image size\")\n",
    "print(\"     - Pull count\")\n",
    "print(\"\\n4. Build Artifacts\")\n",
    "print(\"   - Docker images in registry\")\n",
    "print(\"   - Coverage reports\")\n",
    "print(\"   - Test results\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. Pull and Use Published Image\n",
    "\n",
    "Once the CI pipeline publishes the image, you can pull and use it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Published Docker Image:\n",
      "============================================================\n",
      "\n",
      "# Pull image from Docker Hub\n",
      "docker pull <username>/cats-dogs-classifier:latest\n",
      "\n",
      "# Run the pulled image\n",
      "docker run -d -p 8000:8000 --name cats-dogs-api \\\n",
      "  <username>/cats-dogs-classifier:latest\n",
      "\n",
      "# Test the running container\n",
      "curl http://localhost:8000/health\n",
      "\n",
      "# Available tags:\n",
      "  - latest: Latest build from main branch\n",
      "  - main-<sha>: Specific commit from main\n",
      "  - <branch>: Latest from specific branch\n"
     ]
    }
   ],
   "source": [
    "print(\"Using Published Docker Image:\")\n",
    "print(\"=\" * 60)\n",
    "print(\"\\n# Pull image from Docker Hub\")\n",
    "print(\"docker pull <username>/cats-dogs-classifier:latest\")\n",
    "print(\"\\n# Run the pulled image\")\n",
    "print(\"docker run -d -p 8000:8000 --name cats-dogs-api \\\\\")\n",
    "print(\"  <username>/cats-dogs-classifier:latest\")\n",
    "print(\"\\n# Test the running container\")\n",
    "print(\"curl http://localhost:8000/health\")\n",
    "print(\"\\n# Available tags:\")\n",
    "print(\"  - latest: Latest build from main branch\")\n",
    "print(\"  - main-<sha>: Specific commit from main\")\n",
    "print(\"  - <branch>: Latest from specific branch\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "### ✓ Completed Tasks:\n",
    "\n",
    "1. **Automated Testing**\n",
    "   - 33+ unit tests across 3 test files\n",
    "   - Data preprocessing tests (10+)\n",
    "   - Model utility tests (15+)\n",
    "   - API endpoint tests (8+)\n",
    "   - All tests run via pytest\n",
    "   - Test coverage tracking\n",
    "\n",
    "2. **CI Setup (GitHub Actions)**\n",
    "   - Workflow file: .github/workflows/ci-cd.yml\n",
    "   - Triggers: Push and pull requests\n",
    "   - 3 jobs: Test, Build-and-Push, Deploy\n",
    "   - Automatic dependency installation\n",
    "   - Automated testing on every commit\n",
    "   - Docker image building\n",
    "\n",
    "3. **Artifact Publishing**\n",
    "   - Docker Hub integration\n",
    "   - Automatic image tagging\n",
    "   - Tags: latest, branch name, SHA\n",
    "   - Image caching for faster builds\n",
    "   - Registry configured\n",
    "\n",
    "### CI/CD Pipeline Flow:\n",
    "\n",
    "```\n",
    "Code Push → Test Job → Build Job → Push to Registry → (Optional) Deploy\n",
    "              ↓           ↓            ↓                    ↓\n",
    "           pytest      Docker      Docker Hub          Kubernetes\n",
    "           coverage    build       publish            smoke tests\n",
    "```\n",
    "\n",
    "### Next Steps:\n",
    "- Configure GitHub repository secrets\n",
    "- Push code to GitHub\n",
    "- Verify CI pipeline runs successfully\n",
    "- Check Docker Hub for published images\n",
    "- Proceed to M4 for deployment"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
